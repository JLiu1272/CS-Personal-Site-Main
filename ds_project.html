<!DOCTYPE html>
<html>
<head>
	<!--<link rel="stylesheet" href="style.css">-->
	<title>Jennifer Liu Personal Site</title>
	<meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
  	<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  	<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>

  	<!-- Favicon -->
  	<link rel="shortcut icon" href="images/favicon.png">
</head>
<body>
	<!-- Header -->
	<div class="title">
		<center><h1>Jennifer Liu's （廖智盈）Personal Site</h1></center>
		<center><p>A maker, a lifelong learner, a tech enthusiast</p></center>
		<center><p>人事必将与天地相参，然后乃可以成功</p></center>

		<nav class="navbar navbar-inverse">
		  <div class="container-fluid">
		    <ul class="nav navbar-nav">
		      <li><a href="index.html">About</a></li>
		      <li class="dropdown active"><a class="dropdown-toggle" data-toggle="dropdown" href="#">AI/ML Projects <span class="caret"></span></a>
		        <ul class="dropdown-menu">
		          <li><a href="ds_project.html#GPS_Classifier">GPS Classifier</a></li>
		          <li><a href="ds_project.html#Recipe_Replacement">Recipe Replacement</a></li>
		          <li><a href="ds_project.html#Language_Prediction">Language Prediction</a></li>
		          <li><a href="ds_project.html#PathPlanning">Marathon Runner Route Planning</a></li>
		          <li><a href="ds_project.html#DM_Fundamentals">Data Mining Fundamentals Concepts Implementations</a></li>
		          <li><a href="ds_project.html#Word_Sense_Disambiguation">Word Sense Disambiguation</a></li>
		          <li><a href="ds_project.html#Word_Sense_Disambiguation">Sentiment Analysis</a></li>
		        </ul>
		      </li>
		      <li class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#">Software Engineer Projects <span class="caret"></span></a>
		        <ul class="dropdown-menu">
		          <li><a href="se_project.html#LIUEC_ManagementTool_V1">LIUEC ManagementTool V1</a></li>
		          <li><a href="se_project.html#LIUEC_ManagementTool_V0">LIUEC ManagementTool V0</a></li>
		          <li><a href="se_project.html#Octopus_E_Wallet">Octopus E-Wallet Prototype</a></li>
		          <li><a href="se_project.html#youtube_randomizer">Youtube Randomizer</a></li>
		        </ul>
		      </li>
		      <li class="dropdown"><a class="dropdown-toggle" data-toggle="dropdown" href="#">SMIF (Coming Soon) <span class="caret"></span></a>
		        <ul class="dropdown-menu">
		          <li><a href="smif_startup.html#about_smif">About SMIF</a></li>
		          <!--<li><a href="se_project.html#LIUEC_ManagementTool_V0">Prototype</a></li>-->
		          <!--<li><a href="se_project.html#LIUEC_ManagementTool_V0">We are hiring</a></li>-->
		        </ul>
		      </li>
		      <li><a href="internship.html">Internship</a></li>
		      <li><a href="resume.html">Resume</a></li>
		    </ul>
		  </div>
		</nav>
	</div>

	<center><h1 id="project">AI/ML Projects</h1></center>

	<div class="container">
		<!-- GPS Classifier -->
		<div id="GPS_Classifier">
			<h2>GPS Classifier (2018)</h2>
			<p>We were given a set of GPS data, and were asked to predict when a car
			   stopped due to a stop sign or traffic light, and when a car turned left or right. Additionally, the GPS data was made of many paths, to eliminate the clutters, K-Means was used to agglomerate paths and remove issues related to dilution of precision.</p>
			<p><strong>Methods Used:</strong> DBScan, K-Means, Decision Tree</p>
			<p><strong>Teammates:</strong> Joe Golden, Niccolo Dehicchio</p> 
			<h3>Classifier Results</h3>
			<div class="container">
				<div class="row">
					<div class="col-sm-5"><img src="images/photos/stop_classifier_evidence_1.png" alt="Stop Classifier Evidence" height="100%" width="100%"></div>
    				<div class="col-sm-5"><img src="images/photos/stop_classifier_evidence_2.png" alt="Stop Classifier Evidence" height="100%" width="100%"></div>
				</div>
				<div class="row">
					<div class="col-sm-9"><img src="images/photos/agglomerate_path.png" alt="Stop Classifier Evidence" height="100%" width="100%"></div>
				</div>
				<div class="row">
					<div class="col-sm-5"><img src="images/photos/left_turn_classifier.png" alt="Stop Classifier Evidence" height="100%" width="100%"></div>
				</div>
			</div>
			<br/>
			<strong>Link to Paper:</strong>
			<a href="images/write_ups/CSCI420PROJECT_WRITEUP.pdf">Making Predictions with Vehicle's GPS Data</a>
			<br>
			<strong>Link to Github:</strong>
			<a href="https://github.com/JLiu1272/csci420_proj1">GPS Predictions Github</a>
		</div>

		<!-- Recipe Replacement --> 
		<div id="Recipe_Replacement">
			<h2>Using Word Embedding to automate Recipe Replacement (2018)</h2>
			<p>In this project, we explore the possibility of creating a model that can identify replacement for an ingredient. For instance, if the query was butter, it should discover that margarine is similar to butter, so that is 1 potential replacement. The applications for this are numerous: along with aiding individuals with allergies and dietary restrictions, this can also help cooks understand how to use ingredients they already have. The idea is to transform ingredients into embeddings. With ingredients represented as embeddings, cosine similarity can be used to find the closest replacement.
			</p>
			<img src="images/photos/recipe_replacement_result_1.png" alt="Recipe Replacement Evidence" height="100%" width="100%">
			<img src="images/photos/recipe_replacement_result_2.png" alt="Recipe Replacement Evidence" height="100%" width="100%">
			<br/>
			<br/>
			<strong>Paper Available Below:</strong>
			<a href="images/write_ups/RecipeReplacement.pdf" class="button fit">Using Word Embedding to Automate Recipe Replacement Research Paper</a>
			<br/>
			<strong>Link to Github</strong>
			<a href="https://github.com/JLiu1272/RecipeSubsitutionUsingWordEmbedding">Research Github</a>
		</div>

		<!-- Word Sense Disambiguation --> 
		<div id="Word_Sense_Disambiguation">
			<h2>Word Sense Disambiguation using Decision List</h2>
			<p>The program determines the sense of a word based on context using Decision List proposed by David Yarowsky. The implementation was based on this paper <a href="https://www.aclweb.org/anthology/P94-1013">Decision Lists for Lexical Ambiguity Resolution</a>. In this paper, the author used WSD method to differentiate between two different types of accent. We apply this same method to predict the sense of words. (BASS vs. SAKE)</a></p>
			<p>Currently, the implementation is only capable of determining two word sense (BASS and SAKE). The dataset used for training this decision list is obtained from R.Sproat textbook.</p>
			<strong>How does Decision List work ?</strong>
			<p>We create multiple collocation types based on data. Collocation types used are the window size, the Part of Speech tag of a word, and single words. Using these collocations, multiple if statements are created. The order in which the if statement is traversed is based on the Log-Likelihood of the Decision List. When given a new sentence that contains either a "Bass" or "Sake", it traverses through the if-statements in the sorted order, and returns the result of the if statement. If no match is found, it returns the majority rule. For the word "Bass", there were more sentences that had the musical meaning in the training data. Therefore, if no "if-statements" match, it would default to have the "musical" sense.</p>
			<strong>Log Likelihood Equation</strong>
			<img src="images/photos/wsd/log_likelihood.png" width="50%" height="50%">
			<p>Here is an example. If we were given the sentence, "Stephan Weidner, the composer and bass player for Boehse Onkelz, a", a window size of 2 collocation will generate a list like this; [2_window_composer, 2_window_and, 2_window_player, 2_window_for]. A collocation using Part of Speech tag will replace the respective word with the part of speech of the word based on its context. For example, it may generate a rule like this; -2_tag_noun because composer is a noun, and composer is 2 words left of "bass". A collocation using single words will only consider the word that is n words away from bass. For example, if we are creating a collocation using 2 words to the left, it will only consider composer. Hence, it will generate a rule like this; -2_word_composer.  
			<br/>
			<strong>Summary of Collocations considered</strong>
			<ul>
				<li>Word immediately to the right (+1 W)</li>
				<li>Word immediately to the left (-1 W)</li>
				<li>Word found in (+/- 5) word window (+/)</li>
				<li>Part of Speech Tag of word to the right (Tag + 1 W)</li>
				<li>Part of Speech Tag of word to the left (Tag -1 W)</li>
			</ul>
			<strong>Decision made during Cleaning Corpus:</strong>
			<ul>
				<li>Removed punctuations</li>
				<li>I noticed that there were some xml tags such as <Doc=XXX>. I decided to remove those</li>
				<li>I also removed the dashes in compound words such as 7-pound and concatenated these 2 words together. Resulting in 7pound.</li>
			</ul>
			<h3>Word Sense Disambiguation Results</h3>
			<div class="container">
				<div class="row">
					<div class="col-sm-5"><img src="images/photos/wsd/base_example.png" height="100%" width="100%"></div>
    				<div class="col-sm-5"><img src="images/photos/wsd/sake_example.png" height="100%" width="100%"></div>
				</div>
				<div class="row">
					<h3>Accuracy, Baseline, and Confusion Matrix</h3>
					<p>This table shows the accuracy when predicting on testing data, and it also shows the baseline accuracy for the two words</p>
					<div class="col-sm-5"><img src="images/photos/wsd/wsd_baseline.png" height="100%" width="100%"></div>
				</div>
				<div class="row">
					<div class="col-sm-5"><img src="images/photos/wsd/confusion_matrix.png" alt="Stop Classifier Evidence" height="100%" width="100%"></div>
				</div>
			</div>
			<br/>
			<strong>Link to Github: </strong>
			<a href="https://github.com/JLiu1272/WordSenseDisambiguation">WSD Github</a>
		</div>

		<!-- Sentiment Analysis on Unbalanced Data --> 
		<div id="Sentiment_Analysis">
			<h2>Sentiment Analysis, Genre Prediction, Topic Prediction on Unbalanced Data</h2>
			<p>The data set contains sentences extracted from reviews about products, movies, and resources. The sources of review came from IMDB, Amazon, and Yelp. We were ask to complete 3 Tasks.</p>
			<p><strong>Teammates: </strong>Oliver Olonzo, Josh Bickings</p>
			<ul>
				<li>Task 1: Predict the polarity of the review (Positive, Negative, Neutral).</li>
				<li>Task 2: Predict the event classes/types (i.e Attending_event, Communication_issue, Going_to_places, Legal_issue, None, Money_issue, Outdoor_activity, Personal_care, (Fear_of_Physical_pain)</li>
				<li>Task 3: Identify the source of genre of sentence (2 genre available: genre A or genre B)</li>
			</ul>
			<strong>Implementation Details and Results Available Below:</strong>
			<a href="images/write_ups/OliverAlonzo_JoshBickings_JenniferLiu_SciKitBlackBelt.pdf" class="button fit">Sentiment Analysis Implementation Approach and Results</a>
			<br/>
		</div>

		<!-- Language Prediction --> 
		<div id="Language_Prediction">
			<h2>Predicting language of text (Dutch/English) using Decision Tree and Adaboost (2018)</h2>
			<p>The purpose of this program is to determine whether the sentence is Dutch of English using Decision Tree and Adaboost.</p>
			<strong>Features Summary:</strong><br/>
			<ul>
				<li>Does it contain English/Dutch stop words?</li>
				<li>Most common letter combinations in English/Dutch</li>
				<li>Does it contain an English/Dutch suffix?</li>
			</ul>
			<strong>Testing and Training Sample Details</strong><br/>
			<ul>
				<li>For the training samples, there are 1610, 15 word , sentences scraped through various sources</li>
				<li>713 of the training sample is Dutch, and 897 of them were English sentences</li>
				<li>For the testing samples, there were 404, 15 word sentences</li>
				<li>179 of them were Dutch sentences, and 255 were English sentences</li>
			</ul>
			<img src="images/photos/language_prediction_evidence_1.png" alt="Language Prediction Evidence" height="100%" width="100%">
			<br/>
			<strong>Link to Paper:</strong>
			<a href="images/write_ups/LanguagePrediction_Writeup.pdf">Language Prediction using Decision Tree and Adaboost</a>
			<br/>
			<strong>Link to Github:</strong>
			<a href="https://github.com/JLiu1272/LanguagePredictionUsingDecisionTree">Language Prediction Github</a>
		</div>

		<!-- A* Path Planning -->
		<div id="PathPlanning">
			<h2>Finding shortest route for Marathon Runners using A* (2018)</h2>
			<p>The purpose of this program is to find the shortest route from a start point to a final point defined by the user. However, the runner must pass certain points along the path in order to get to its final destination. In addition, the elevation, and terrain type must be considered when finding the shortest path. The terrain and its ability to impede a runner may change depending on the season. Details about how the heuristic for the A* is outlined in the "Link to paper" section.</p>
			<img src="images/photos/path_planning_evidence.png" alt="Path Evidence" height="100%" width="100%">
			<p><strong>Figures:</strong> The path found is shown in red, and the blue points along the red paths are representative of the "must pass" points.</p>
			<strong>Link to Paper:</strong>
			<a href="images/write_ups/shortestPath_Paper.pdf">Shortest Path for Marathon Runner Paper</a>
		</div>

		<!-- Data Mining Fundamental Concepts Implementations --> 
		<div id="DM_Fundamentals">
			<h2>Implementation of Fundamental Data Mining Concepts from Scratch (2018)</h2>
			<h3>Concepts implemented include:</h3>
			<ul>
				<li>Agglomeration (Agglomerated locations on a map)</li>
				<li>Otsu's Method (Used method to find best car speed when considering whether someone is speeding or not)</li>
				<li>PCA (Projected 120 dimension data onto 3 dimension)</li>
				<li>KNN (Used KNN to classify different types of shoppers at a grocery store)</li>
				<li>K-Means (performed k-means on carefully constructed data)</li>
			</ul>
			<strong>All implementations are compiled in this github link: </strong>
			<a href="https://github.com/JLiu1272/DataMiningFundamentals">Fundamental Concept Implementations</a>

			<h3>K-Means Result</h3>
			<a href="https://github.com/JLiu1272/DataMiningFundamentals/blob/master/kMeans.py">K-Means Github Code</a>
			<br/>
			<img src="images/photos/KMeans_Result.png" alt="K-Means Result" width="100%" height="100%">

			<h3>Agglomeration Result on random map locations</h3>
			<a href="https://github.com/JLiu1272/DataMiningFundamentals/blob/master/Agglomeration.py">Agglomeration Github Code</a>
			<br/>
			<img src="images/photos/agglomeration.png" alt="Agglomeration Result" width="100%" height="100%">

			<h3>PCA Visual Results</h3>
			<a href="https://github.com/JLiu1272/DataMiningFundamentals/blob/master/PCA_and_KNN.py">PCA Github Code</a>
			<br/>
			<p>First, we agglomerated the data points. Then, we used PCA to project 120 Dimensional data to 3 Dimension. After projecting it, we were able to visualise it as a 3D plot</p> 
			<img src="images/photos/PCA_Agglomeration.png" width="100%" height="100%">
		</div>
	</div>
</body>
</html>